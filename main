import os
from PIL import Image
from keras.src.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau
from keras.src.legacy.preprocessing.image import ImageDataGenerator
from matplotlib import pyplot as plt

from keras.layers import *
from keras.models import *
from keras.optimizers import *
from keras import *




root = 'C:/Users/Silas/Downloads/arch_1/images/images/train'
root2 = 'C:/Users/Silas/Downloads/arch_1/images/images/validation'

fnames = os.listdir(root)

fig, axs = plt.subplots(nrows=2, ncols=4)
axs = axs.flatten()

#iterate through emotion folders
for i in range(7):
    #create a path to an emotion folder
    filepath = os.path.join(root, fnames[i])
    #create an axis title to match
    axs[i].set_title(fnames[i])
    fimgs = os.listdir(filepath)
    #iterate through images in each emotion folder
    for x in range(1):
        #directory of images in folder
        filepath = os.path.join(filepath, fimgs[x])
        #open current img and display it
        current_img = Image.open(filepath)
        axs[i].imshow(current_img)
        axs[i].axis('off')
plt.show()


#create an image data set for test and training
batchSize = 10
data_train = ImageDataGenerator()
data_test = ImageDataGenerator()

#load the training data into a set
train_set = data_train.flow_from_directory(root, target_size=(48, 48),
        color_mode="grayscale", batch_size=batchSize,
        class_mode='categorical', shuffle=True)
test_set = data_train.flow_from_directory(root2, target_size=(48, 48),
        color_mode="grayscale", batch_size=batchSize,
        class_mode='categorical', shuffle=False)


#define the number of emotion classes and the type of model
classes = 7
model = Sequential()

#create the first layer
model.add(Conv2D(64, (3,3), padding = 'same', input_shape = (48,48,1)))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.25))

#create the second layer
model.add(Conv2D(128, (3,3), padding = 'same'))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.25))

#create the third layer
model.add(Conv2D(512, (3,3), padding = 'same'))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.25))

#create the fourth layer
model.add(Conv2D(512, (3,3), padding = 'same'))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.25))

model.add(Flatten())

#connect the first layer
model.add(Dense(256))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(Dropout(0.25))

#connect the first layer
model.add(Dense(512))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(Dropout(0.25))

model.add(Dense(classes, activation='softmax'))

checkpoint = ModelCheckpoint("./model.keras", monitor='val_acc',
                             verbose=1, save_best_only=True, mode='max')
early_stopping = EarlyStopping(monitor='val_loss',
                               min_delta=0,
                               patience=3,
                               verbose=1,
                               restore_best_weights=True)

reduce_learningrate= ReduceLROnPlateau(monitor='val_loss',
                                       factor=0.2,
                                       patience=3,
                                       verbose=1,
                                       min_delta=0.001)
callbacks_list = [early_stopping, checkpoint, reduce_learningrate]
opt = Adam(learning_rate=0.001)
model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])
model.summary()

epochs = 48

model.compile(loss='categorical_crossentropy',
              optimizer = Adam(learning_rate=0.01),
              metrics=['accuracy'])

history = model.fit(train_set,
                                steps_per_epoch=train_set.n//train_set.batch_size,
                                epochs=epochs,
                                validation_data = test_set,
                                validation_steps = test_set.n//test_set.batch_size,
                                callbacks=callbacks_list
                                )
